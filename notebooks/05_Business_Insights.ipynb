{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 05. Business Actionable Insights & Evaluation\n",
                "\n",
                "**Objective**: Translate technical clustering results into professional business strategies. We evaluate all three candidate models (K-Means, DBSCAN, Hierarchical) to provide a recommendation based on interpretability and actionable segmentation.\n",
                "\n",
                "**Key Techniques:**\n",
                "*   **Radar Charts**: Visualize the \"personality\" of each cluster (e.g., \"High Spenders\" vs. \"Bargain Hunters\").\n",
                "*   **SHAP Values**: Explain *why* a customer falls into a specific cluster (Feature Importance).\n",
                "*   **Business Profiling**: Define personas and marketing strategies."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "d:\\python_envs\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "import sys\n",
                "sys.path.append('../src')\n",
                "from clustering_library import ClusterAnalyzer, DataVisualizer\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import shap\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data & Clustering Results\n",
                "\n",
                "We load the scaled features (for technical analysis/SHAP) and the original features (for business profiling), along with the cluster labels saved from the Validation step."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Số khách hàng: 3920\n",
                        "Số features: 16\n",
                        "Columns in df_original: ['Sum_Quantity', 'Mean_UnitPrice', 'Mean_TotalPrice', 'Sum_TotalPrice', 'Count_Invoice', 'Count_Stock', 'Mean_InvoiceCountPerStock', 'Mean_StockCountPerInvoice', 'Mean_UnitPriceMeanPerInvoice', 'Mean_QuantitySumPerInvoice', 'Mean_TotalPriceMeanPerInvoice', 'Mean_TotalPriceSumPerInvoice', 'Mean_UnitPriceMeanPerStock', 'Mean_QuantitySumPerStock', 'Mean_TotalPriceMeanPerStock', 'Mean_TotalPriceSumPerStock']\n",
                        "Loaded clustering results successfully.\n",
                        "            Cluster_KMeans  Cluster_DBSCAN  Cluster_Hierarchical\n",
                        "CustomerID                                                      \n",
                        "12346                    1              -1                     0\n",
                        "12747                    1               0                     2\n",
                        "12748                    2              -1                     2\n",
                        "12749                    2               0                     2\n",
                        "12820                    2               0                     2\n"
                    ]
                }
            ],
            "source": [
                "analyzer = ClusterAnalyzer()\n",
                "df_scaled, df_original = analyzer.load_data()\n",
                "\n",
                "rename_map = {\n",
                "    'recency': 'Recency',\n",
                "    'frequency': 'Frequency',\n",
                "    'monetary': 'Monetary',\n",
                "    'tenure': 'Tenure'\n",
                "}\n",
                "df_original.rename(columns=rename_map, inplace=True)\n",
                "print(\"Columns in df_original:\", df_original.columns.tolist())\n",
                "\n",
                "# Load pre-computed labels\n",
                "try:\n",
                "    results_df = pd.read_csv(\"../data/processed/clustered_customers.csv\", index_col=0)\n",
                "    print(\"Loaded clustering results successfully.\")\n",
                "    print(results_df.head())\n",
                "except FileNotFoundError:\n",
                "    print(\"Error: '../data/processed/clustered_customers.csv' not found. Please run 04_Technical_Validation.ipynb first.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Comparative Business Evaluation\n",
                "\n",
                "We will iterate through each model to generate profiles and explainability visuals."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "models = ['KMeans', 'DBSCAN', 'Hierarchical']\n",
                "\n",
                "for model_name in models:\n",
                "    col_name = f'Cluster_{model_name}'\n",
                "    if col_name not in results_df.columns:\n",
                "        print(f\"\\nSkipping {model_name} (Labels not found)\")\n",
                "        continue\n",
                "        \n",
                "    print(f\"\\n{'='*20} ANALYZING MODEL: {model_name} {'='*20}\")\n",
                "    \n",
                "    # Get labels\n",
                "    labels = results_df[col_name].values\n",
                "    \n",
                "    # Handle Noise in DBSCAN for profiling (usually exclude -1 or treat separately)\n",
                "    # We'll treat -1 as a distinct group for visualization\n",
                "    unique_labels = np.unique(labels)\n",
                "    n_clusters = len(unique_labels) - (1 if -1 in unique_labels else 0)\n",
                "    print(f\"Number of Clusters: {n_clusters} (Noise points: {np.sum(labels == -1)})\\n\")\n",
                "    \n",
                "    if n_clusters < 1 and np.sum(labels == -1) == 0:\n",
                "        print(\"No valid clusters and no noise. Skipping.\")\n",
                "        continue\n",
                "    elif n_clusters < 2:\n",
                "        print(\"Note: Only 1 cluster found (plus noise). Analyzing as Single Group vs Noise.\")\n",
                "\n",
                "    # --- 2.1. Cluster Statistics ---\n",
                "    # Merge labels with original data for interpretable means\n",
                "    df_business = df_original.copy()\n",
                "    df_business['Cluster'] = labels\n",
                "    \n",
                "    cluster_means = df_business.groupby('Cluster').mean()\n",
                "    cluster_sizes = df_business['Cluster'].value_counts().sort_index()\n",
                "    \n",
                "    print(\"Cluster Sizes:\")\n",
                "    print(cluster_sizes)\n",
                "    print(\"\\nCluster Profiles (Key Metrics Mean):\")\n",
                "    \n",
                "    # Display specific RFM columns if available, otherwise all\n",
                "    cols_to_show = ['Recency', 'Frequency', 'Monetary']\n",
                "    available_cols = [c for c in cols_to_show if c in cluster_means.columns]\n",
                "    if available_cols:\n",
                "        display(cluster_means[available_cols].round(2))\n",
                "    else:\n",
                "        print(\"RFM columns not found for profile display, showing all:\")\n",
                "        display(cluster_means.round(2))\n",
                "\n",
                "    # --- 2.2. Radar Chart Visualization ---\n",
                "    print(f\"\\nGenerating Radar Chart for {model_name}...\")\n",
                "    # Manually inject into analyzer to allow helper methods to work\n",
                "    # Note: create_radar_chart typically expects labels 0..k-1. \n",
                "    # DBSCAN might have -1. simple workaround: let analyzer handle it via 'labels' arg if supported, or filter.\n",
                "    try:\n",
                "        # The `create_radar_chart` in library likely expects labels. \n",
                "        # We filter out noise for Radar Chart clarity if it's DBSCAN\n",
                "        clean_mask = labels != -1\n",
                "        if np.sum(clean_mask) > 0:\n",
                "            # We also need to temporarily update analyzer.df_original because helper methods might use it\n",
                "            # Ensure analyzer has the standardized columns\n",
                "            analyzer.df_original = df_original[clean_mask].copy()\n",
                "            \n",
                "            analyzer.create_radar_chart(labels=labels[clean_mask])\n",
                "            \n",
                "            # --- 2.2b. Individual Cluster Profiles ---\n",
                "            print(f\"\\nGenerating Individual Radar Plots for {model_name}...\")\n",
                "            # Ensure we use the correct key (k_key) which we set for SHAP later, but we need to set it NOW if we use it here.\n",
                "            # However, looking at the code structure, k_key is defined later for SHAP.\n",
                "            # We need to manually register the means for create_individual_radar_plots to work.\n",
                "            \n",
                "            # Re-calculate means using the clean mask to match the visualization data\n",
                "            clean_labels = labels[clean_mask]\n",
                "            \n",
                "            # If DBSCAN, n_clusters might be 1, but we want to plot whatever valid clusters we found.\n",
                "            # create_individual_radar_plots uses self.cluster_results[k][\"means\"]\n",
                "            \n",
                "            # We'll stick to a temporary key = 999 or just reuse n_clusters if unique\n",
                "            temp_key = n_clusters if n_clusters > 0 else 1\n",
                "            \n",
                "            # Prepare a temporary dataframe to calc means exactly as the library expects\n",
                "            temp_df = df_original[clean_mask].copy()\n",
                "            temp_df['Cluster'] = clean_labels\n",
                "            temp_means = temp_df.groupby('Cluster').mean()\n",
                "            \n",
                "            # Inject into analyzer\n",
                "            analyzer.cluster_results[temp_key] = {\n",
                "                'labels': clean_labels,\n",
                "                'means': temp_means\n",
                "            }\n",
                "            \n",
                "            try:\n",
                "                analyzer.create_individual_radar_plots(temp_key)\n",
                "            except Exception as e:\n",
                "                print(f\"Could not generate Individual Radar Plots: {e}\")\n",
                "                import traceback\n",
                "                traceback.print_exc()\n",
                "        else:\n",
                "            print(\"No non-noise data to plot.\")\n",
                "    except Exception as e:\n",
                "        print(f\"Could not generate Radar Chart: {e}\")\n",
                "\n",
                "    # --- 2.3. Explainability (SHAP) ---\n",
                "    print(f\"\\nCalculating SHAP values for {model_name}...\")\n",
                "    \n",
                "    # We need to register the results in analyzer to use its training/SHAP methods\n",
                "    # The helper methods use integer keys (k). We'll use a dummy integer key relative to n_clusters\n",
                "    # or modify state directly.\n",
                "    \n",
                "    k_key = n_clusters\n",
                "    analyzer.cluster_results[k_key] = {\n",
                "        'labels': labels,\n",
                "        'means': cluster_means\n",
                "    }\n",
                "\n",
                "    try:\n",
                "        # 1. Train Surrogate Random Forest\n",
                "        analyzer.train_surrogate_model(k_key)\n",
                "        \n",
                "        # 2. Calculate SHAP\n",
                "        analyzer.calculate_shap_values(k_key)\n",
                "        \n",
                "        # 3. Plot SHAP Summary\n",
                "        print(f\"SHAP Summary Plot for {model_name}:\")\n",
                "        analyzer.plot_shap_summary(k_key)\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"Error in SHAP analysis for {model_name}: {e}\")\n",
                "        # Traceback often helps debugging SHAP version/library issues\n",
                "        # import traceback\n",
                "        # traceback.print_exc()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "myenv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}